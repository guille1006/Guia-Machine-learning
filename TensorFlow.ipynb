{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab35684",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">TensorFlow</h1>\n",
    "<h1 style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo Díaz Aguado</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e1ff55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 7777\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1d3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import re\n",
    "\n",
    "# Solo filtra la advertencia específica sobre input_shape en Sequential\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=re.escape(\"Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\"),\n",
    "    category=UserWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a49a8",
   "metadata": {},
   "source": [
    "# Tensores y variables\n",
    "TensorFlow opera en arreglos multidimensionales o **tensores** representados como objetos `tf.Tensor`.\n",
    "Tiene las caracterisiticas de:\n",
    "* `Tensor.shape`: te dice las dimensiones de estos *tensores*.\n",
    "    * ⚠️ Deben ser matrices rectangulares\n",
    "* `Tensor.dtype`: te dice el tipo de todos los elementos del *tensor. \n",
    "    * ⚠️ Todos los valores deben ser del mismo tipo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018e690",
   "metadata": {},
   "source": [
    " Estos *tensores* son *matrices multidimensionales* que ademas se comportan de una forma muy parecida a los de `nunpy`:\n",
    "\n",
    "* Con respecto a los cálculos matemáticos:\n",
    "\n",
    "| Tipo de cálculo / operación            | ¿Es similar? | NumPy (`np.ndarray`)      | TensorFlow (`tf.Tensor`)                                      | Notas                               |\n",
    "| -------------------------------------- | ------------ | ------------------------- | ------------------------------------------------------------- | ----------------------------------- |\n",
    "| **Suma de arrays/matrices**            | ✅ Sí         | `a + b`                   | `a + b`                                                       | Idéntica                            |\n",
    "| **Resta de arrays/matrices**           | ✅ Sí         | `a - b`                   | `a - b`                                                       | Idéntica                            |\n",
    "| **Multiplicación elemento a elemento** | ✅ Sí         | `a * b`                   | `a * b`                                                       | Igual                               |\n",
    "| **Producto matricial (dot product)**   | ✅ Sí         | `np.dot(a, b)`            | `tf.matmul(a, b)`                                             | Función diferente                   |\n",
    "| **Transposición**                      | ✅ Sí         | `a.T` o `np.transpose(a)` | `tf.transpose(a)`                                             | Sintaxis parecida                   |\n",
    "| **Slicing / Indexing**                 | ✅ Sí         | `a[0, :]`                 | `a[0, :]`                                                     | Idéntica                            |\n",
    "| **Broadcasting**                       | ✅ Sí         | Automático                | Automático                                                    | Muy parecido                        |\n",
    "| **Suma por ejes (axis)**               | ✅ Sí         | `np.sum(a, axis=0)`       | `tf.reduce_sum(a, axis=0)`                                    | Funciones distintas                 |\n",
    "| **Mean / promedio**                    | ✅ Sí         | `np.mean(a)`              | `tf.reduce_mean(a)`                                           | Diferente nombre                    |\n",
    "| **Varianza / desviación típica**       | ✅ Sí         | `np.var(a)`               | `tf.math.reduce_variance(a)`                                  | TF usa `tf.math`                    |\n",
    "| **Funciones trigonométricas**          | ✅ Sí         | `np.sin(a)`               | `tf.math.sin(a)`                                              | Misma lógica                        |\n",
    "| **Funciones log, exp, sqrt, etc.**     | ✅ Sí         | `np.log(a)`               | `tf.math.log(a)`                                              | Prefijo `math.`                     |\n",
    "| **Reshape / cambio de forma**          | ✅ Sí         | `a.reshape((2, 4))`       | `tf.reshape(a, (2, 4))`                                       | Igual                               |\n",
    "| **Stack / concat / split**             | ✅ Sí         | `np.concatenate([...])`   | `tf.concat([...])`                                            | Igual lógica                        |\n",
    "| **Argmax / argmin**                    | ✅ Sí         | `np.argmax(a)`            | `tf.argmax(a)`                                                | Igual                               |\n",
    "| **Sort / argsort**                     | ✅ Sí         | `np.sort(a)`              | `tf.sort(a)`                                                  | Igual                               |\n",
    "| **Boolean masking / filtrado**         | ✅ Sí         | `a[a > 0]`                | `tf.boolean_mask(a, a > 0)`                                   | Similar pero con función específica |\n",
    "| **Operaciones en GPU**                 | ❌ No         | ❌ No                      | ✅ Sí (automático)                                             | Gran diferencia                     |\n",
    "| **Autodiferenciación (gradientes)**    | ❌ No         | ❌ No                      | ✅ Sí (`tf.GradientTape`)                                      | Solo TF                             |\n",
    "| **Ejecución simbólica / gráfica**      | ❌ No         | ❌ No                      | ✅ Sí (modo gráfico o eager)                                   | Solo TF                             |\n",
    "| **Mutabilidad (modificar valores)**    | ❌ No         | ✅ Sí (`a[0,0] = 5`)       | ❌ No (`tf.Tensor` es inmutable)                               | Solo mutable en NumPy               |\n",
    "| **Conversión a lista**                 | ✅ Sí         | `a.tolist()`              | `a.numpy().tolist()`                                          | En TF necesitas `.numpy()` primero  |\n",
    "| **Guardar en disco (formato nativo)**  | ✅ Similar    | `np.save()` / `np.load()` | `tf.saved_model` (modelos), o `.numpy()` para exportar arrays | Diferente enfoque                   |\n",
    "\n",
    "Y con respecto a sus caracteristicas:\n",
    "\n",
    "| Característica                   | **NumPy array**            | **TensorFlow tensor**                         |\n",
    "| -------------------------------- | -------------------------- | --------------------------------------------- |\n",
    "| Tipo                             | `numpy.ndarray`            | `tf.Tensor`                                   |\n",
    "| Biblioteca                       | NumPy                      | TensorFlow                                    |\n",
    "| Uso principal                    | Cálculo científico general | Computación automática (ML/DL)                |\n",
    "| Soporte para GPU                 | ❌ No (solo CPU)            | ✅ Sí (GPU, TPU, CPU)                          |\n",
    "| Diferenciación automática        | ❌ No                       | ✅ Sí (con `tf.GradientTape`)                  |\n",
    "| Computación simbólica            | ❌ No                       | ✅ Sí (gráficos computacionales)               |\n",
    "| Inmutabilidad                    | ✅ Mutable                  | ⚠️ Inmutable (no puedes cambiar su contenido) |\n",
    "| Integración con redes neuronales | ❌ No directo               | ✅ Nativo (keras, optimizers, etc.)            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e9e4c",
   "metadata": {},
   "source": [
    "## Tensor constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f603babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "()\n",
      "tf.Tensor([17 12], shape=(2,), dtype=int32)\n",
      "(2,)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = tf.constant(18)\n",
    "print(scalar)\n",
    "print(scalar.shape)\n",
    "\n",
    "# Vector\n",
    "vector = tf.constant([17, 12])\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "\n",
    "# Matrices\n",
    "matrix = tf.constant([[1, 2],\n",
    "                      [3, 4]])\n",
    "print(matrix)\n",
    "print(matrix.shape)\n",
    "\n",
    "# Tensor\n",
    "tensor = tf.constant([[[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8e03b",
   "metadata": {},
   "source": [
    "# First Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e782d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8a305",
   "metadata": {},
   "source": [
    "## Input\n",
    "Para definir la usamos el objeto `Input`. Debe ser el numero de variables independientes.\n",
    "* `shape`: dimensión de entrada, tiene que estar en el formato de (input_dimension,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9e155",
   "metadata": {},
   "source": [
    "## Dense\n",
    "Podemos crear capas *completamente conectadas* usando la clase `Dense`. \n",
    "Tiene lso siguientes parametros:\n",
    "* `units`: Número de neuronas en esa capa.\n",
    "* `activation`: Función de activación que usaremos. Por defecto está la función *lineal* .\n",
    "* `name`: Es interesante poner el nombre de cada capa para poder identificarlas.\n",
    "* `input_shape`: En caso de no querer usar el objeto `Input`, podemos incluir una primera capa que tenga este atributo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8151fb",
   "metadata": {},
   "source": [
    "## Sequential\n",
    "El objeto `Sequential` <u> es donde vamos a crear nuestra red neuronal </u>. Tenemos dos formas para crearlo:\n",
    "1. * Crear el objeto\n",
    "    * Vamos añadiendo las capas con el método **.add** a nuestro objeto\n",
    "    * Recordar que la primera capa debe ser `Input` o `Dense`(con el atributo de *input_shape*)\n",
    "2. * Podemos guardar directamente el modelo con todas las capas guardadas en una lista.\n",
    "    * Además también se pueden añadir más capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8ed9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential()\n",
    "model1.add(layers.Dense(3, activation=\"sigmoid\", name=\"input_lay\", input_shape=(2,)))\n",
    "model1.add(layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\"))\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    keras.Input(shape=(2,)),\n",
    "    layers.Dense(3, activation=\"sigmoid\", name=\"input_layer\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985f6bd",
   "metadata": {},
   "source": [
    "# Guardar y cargar modelos de Keras\n",
    "## Guardar modelo\n",
    "Puedes guardar facilmente tu modelo entero (arquitectura, pesos, optimizer state) usando el método `save` y ponemos el nombre del archivo que lo queremos guardar, importante poner el sufijo \".keras\" o \".h5\".\n",
    "* .keras: El modo recomnedado y por defecto para TenserFlow 2.12. Incluye metadata del modelo y es \"future-proof\".\n",
    "* .h5: Es muy usado y es muy simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb62abd",
   "metadata": {},
   "source": [
    "`model1.save(\"Modelo_Keras.keras\")`\n",
    "\n",
    "`model1.save(\"Modelo2_Keras.h5\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb8eaf",
   "metadata": {},
   "source": [
    "## Cargar un modelo. \n",
    "Simplemente debemos llamar a la funcion `load_model` y escribir el nombre del archivo donde esté guardado el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7c19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "modelo_cargado = load_model(\"Modelo_Keras.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd456c9",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740424bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "seed = 7777\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc8c841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargo el datset\n",
    "mnist = tf.keras.datasets.mnist   \n",
    "\n",
    "# Pongo los valores de train y test\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Como son valores de 0 a 255 puedo normalizarlo dividiendo entre 255\n",
    "X_train, X_test = X_train/255.0, X_test/255.0\n",
    "\n",
    "i_rand = np.random.randint(0, len(X_train))\n",
    "plt.imshow(X_train[i_rand])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b153b9",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer más pequeño nuestro dataset de test para que tengamos aun mas **OVERFITTING**.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b4a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, X, _, y = train_test_split(X_train, y_train, test_size=0.2, random_state=seed, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5261aa6",
   "metadata": {},
   "source": [
    "## Creación del modelo\n",
    "Vamos a crear un modelo que sea capaz de generalizar. Nuestro modelo consistirá en :\n",
    "* Input de dimensión 28,28\n",
    "* Capa de flatten (para así tener los datos en una lista)\n",
    "* 3 Dense hidden layer \n",
    "* Output layer con una sola neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a597e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"try_not_overfit\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"try_not_overfit\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,658</span> (983.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m251,658\u001b[0m (983.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,658</span> (983.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m251,658\u001b[0m (983.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28), name=(\"input_layer\"))\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "l_1 = layers.Dense(256, activation=\"relu\", name=\"layer_1\")(flat)\n",
    "l_2 = layers.Dense(128, activation=\"relu\", name=\"layer_2\")(l_1)\n",
    "l_3 = layers.Dense(128, activation=\"relu\", name=\"layer_3\")(l_2)\n",
    "\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(l_3)\n",
    "\n",
    "# Definimos el modelo\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"try_not_overfit\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff2ba6",
   "metadata": {},
   "source": [
    "Ahora usaremos la siguiente configuración para entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e29795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7092 - loss: 0.9929 - val_accuracy: 0.9154 - val_loss: 0.3080\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9276 - loss: 0.2442 - val_accuracy: 0.9350 - val_loss: 0.2270\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9570 - loss: 0.1504 - val_accuracy: 0.9458 - val_loss: 0.1943\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9717 - loss: 0.0995 - val_accuracy: 0.9429 - val_loss: 0.2060\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9805 - loss: 0.0674 - val_accuracy: 0.9371 - val_loss: 0.2439\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0540 - val_accuracy: 0.9500 - val_loss: 0.2030\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9885 - loss: 0.0383 - val_accuracy: 0.9550 - val_loss: 0.1739\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0219 - val_accuracy: 0.9546 - val_loss: 0.2038\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0190 - val_accuracy: 0.9571 - val_loss: 0.1961\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0132 - val_accuracy: 0.9600 - val_loss: 0.1885\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9960 - loss: 0.0132 - val_accuracy: 0.9479 - val_loss: 0.2645\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.0290 - val_accuracy: 0.9542 - val_loss: 0.2041\n",
      "Epoch 13/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 0.0160 - val_accuracy: 0.9538 - val_loss: 0.2003\n",
      "Epoch 14/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0139 - val_accuracy: 0.9579 - val_loss: 0.2204\n",
      "Epoch 15/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9958 - loss: 0.0133 - val_accuracy: 0.9604 - val_loss: 0.2141\n",
      "Epoch 16/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.0089 - val_accuracy: 0.9517 - val_loss: 0.2389\n",
      "Epoch 17/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0169 - val_accuracy: 0.9650 - val_loss: 0.1919\n",
      "Epoch 18/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.9654 - val_loss: 0.1929\n",
      "Epoch 19/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9646 - val_loss: 0.1836\n",
      "Epoch 20/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9642 - val_loss: 0.2056\n",
      "Epoch 21/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9671 - val_loss: 0.1980\n",
      "Epoch 22/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9617 - val_loss: 0.2249\n",
      "Epoch 23/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9371 - val_loss: 0.3491\n",
      "Epoch 24/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0263 - val_accuracy: 0.9425 - val_loss: 0.3251\n",
      "Epoch 25/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9876 - loss: 0.0452 - val_accuracy: 0.9533 - val_loss: 0.2382\n",
      "Epoch 26/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9964 - loss: 0.0138 - val_accuracy: 0.9679 - val_loss: 0.1858\n",
      "Epoch 27/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9683 - val_loss: 0.1785\n",
      "Epoch 28/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9989 - loss: 0.0023 - val_accuracy: 0.9688 - val_loss: 0.1813\n",
      "Epoch 29/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.1233e-04 - val_accuracy: 0.9683 - val_loss: 0.1883\n",
      "Epoch 30/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.5527e-04 - val_accuracy: 0.9692 - val_loss: 0.1892\n",
      "Epoch 31/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 9.3345e-05 - val_accuracy: 0.9696 - val_loss: 0.1913\n",
      "Epoch 32/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 7.5163e-05 - val_accuracy: 0.9696 - val_loss: 0.1932\n",
      "Epoch 33/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.2747e-05 - val_accuracy: 0.9696 - val_loss: 0.1951\n",
      "Epoch 34/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.3538e-05 - val_accuracy: 0.9696 - val_loss: 0.1970\n",
      "Epoch 35/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.6346e-05 - val_accuracy: 0.9696 - val_loss: 0.1987\n",
      "Epoch 36/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.0576e-05 - val_accuracy: 0.9700 - val_loss: 0.2004\n",
      "Epoch 37/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.5820e-05 - val_accuracy: 0.9700 - val_loss: 0.2020\n",
      "Epoch 38/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.1846e-05 - val_accuracy: 0.9696 - val_loss: 0.2036\n",
      "Epoch 39/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.8431e-05 - val_accuracy: 0.9696 - val_loss: 0.2053\n",
      "Epoch 40/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.5491e-05 - val_accuracy: 0.9696 - val_loss: 0.2069\n",
      "Epoch 41/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.2947e-05 - val_accuracy: 0.9700 - val_loss: 0.2085\n",
      "Epoch 42/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.0721e-05 - val_accuracy: 0.9704 - val_loss: 0.2101\n",
      "Epoch 43/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.8756e-05 - val_accuracy: 0.9704 - val_loss: 0.2117\n",
      "Epoch 44/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.6971e-05 - val_accuracy: 0.9704 - val_loss: 0.2133\n",
      "Epoch 45/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5369e-05 - val_accuracy: 0.9704 - val_loss: 0.2149\n",
      "Epoch 46/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.3974e-05 - val_accuracy: 0.9704 - val_loss: 0.2164\n",
      "Epoch 47/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2727e-05 - val_accuracy: 0.9700 - val_loss: 0.2179\n",
      "Epoch 48/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.1607e-05 - val_accuracy: 0.9700 - val_loss: 0.2194\n",
      "Epoch 49/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0599e-05 - val_accuracy: 0.9696 - val_loss: 0.2209\n",
      "Epoch 50/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6893e-06 - val_accuracy: 0.9696 - val_loss: 0.2224\n",
      "Epoch 51/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.8686e-06 - val_accuracy: 0.9692 - val_loss: 0.2239\n",
      "Epoch 52/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.1262e-06 - val_accuracy: 0.9688 - val_loss: 0.2254\n",
      "Epoch 53/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.4551e-06 - val_accuracy: 0.9688 - val_loss: 0.2269\n",
      "Epoch 54/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.8420e-06 - val_accuracy: 0.9688 - val_loss: 0.2285\n",
      "Epoch 55/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.2825e-06 - val_accuracy: 0.9683 - val_loss: 0.2300\n",
      "Epoch 56/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.7721e-06 - val_accuracy: 0.9683 - val_loss: 0.2315\n",
      "Epoch 57/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.3071e-06 - val_accuracy: 0.9688 - val_loss: 0.2331\n",
      "Epoch 58/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.8837e-06 - val_accuracy: 0.9688 - val_loss: 0.2346\n",
      "Epoch 59/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.4969e-06 - val_accuracy: 0.9683 - val_loss: 0.2361\n",
      "Epoch 60/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1424e-06 - val_accuracy: 0.9683 - val_loss: 0.2376\n",
      "Epoch 61/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.8158e-06 - val_accuracy: 0.9683 - val_loss: 0.2392\n",
      "Epoch 62/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.5147e-06 - val_accuracy: 0.9683 - val_loss: 0.2407\n",
      "Epoch 63/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2377e-06 - val_accuracy: 0.9688 - val_loss: 0.2423\n",
      "Epoch 64/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.9839e-06 - val_accuracy: 0.9688 - val_loss: 0.2438\n",
      "Epoch 65/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.7527e-06 - val_accuracy: 0.9688 - val_loss: 0.2453\n",
      "Epoch 66/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5396e-06 - val_accuracy: 0.9688 - val_loss: 0.2468\n",
      "Epoch 67/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.3429e-06 - val_accuracy: 0.9688 - val_loss: 0.2483\n",
      "Epoch 68/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1614e-06 - val_accuracy: 0.9688 - val_loss: 0.2499\n",
      "Epoch 69/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.9950e-06 - val_accuracy: 0.9688 - val_loss: 0.2514\n",
      "Epoch 70/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.8417e-06 - val_accuracy: 0.9688 - val_loss: 0.2530\n",
      "Epoch 71/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7012e-06 - val_accuracy: 0.9688 - val_loss: 0.2545\n",
      "Epoch 72/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.5704e-06 - val_accuracy: 0.9688 - val_loss: 0.2561\n",
      "Epoch 73/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4500e-06 - val_accuracy: 0.9688 - val_loss: 0.2576\n",
      "Epoch 74/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.3376e-06 - val_accuracy: 0.9688 - val_loss: 0.2591\n",
      "Epoch 75/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.2355e-06 - val_accuracy: 0.9688 - val_loss: 0.2607\n",
      "Epoch 76/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1416e-06 - val_accuracy: 0.9688 - val_loss: 0.2621\n",
      "Epoch 77/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.0552e-06 - val_accuracy: 0.9688 - val_loss: 0.2636\n",
      "Epoch 78/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.7492e-07 - val_accuracy: 0.9688 - val_loss: 0.2652\n",
      "Epoch 79/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 9.0110e-07 - val_accuracy: 0.9688 - val_loss: 0.2667\n",
      "Epoch 80/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.3202e-07 - val_accuracy: 0.9688 - val_loss: 0.2682\n",
      "Epoch 81/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.6998e-07 - val_accuracy: 0.9688 - val_loss: 0.2697\n",
      "Epoch 82/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1159e-07 - val_accuracy: 0.9688 - val_loss: 0.2712\n",
      "Epoch 83/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.5928e-07 - val_accuracy: 0.9688 - val_loss: 0.2726\n",
      "Epoch 84/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.0979e-07 - val_accuracy: 0.9688 - val_loss: 0.2741\n",
      "Epoch 85/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.6481e-07 - val_accuracy: 0.9688 - val_loss: 0.2756\n",
      "Epoch 86/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.2189e-07 - val_accuracy: 0.9688 - val_loss: 0.2771\n",
      "Epoch 87/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.8275e-07 - val_accuracy: 0.9683 - val_loss: 0.2785\n",
      "Epoch 88/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4702e-07 - val_accuracy: 0.9683 - val_loss: 0.2800\n",
      "Epoch 89/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.1354e-07 - val_accuracy: 0.9683 - val_loss: 0.2815\n",
      "Epoch 90/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.8261e-07 - val_accuracy: 0.9683 - val_loss: 0.2830\n",
      "Epoch 91/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.5438e-07 - val_accuracy: 0.9683 - val_loss: 0.2843\n",
      "Epoch 92/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2772e-07 - val_accuracy: 0.9683 - val_loss: 0.2858\n",
      "Epoch 93/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.0330e-07 - val_accuracy: 0.9683 - val_loss: 0.2872\n",
      "Epoch 94/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.8119e-07 - val_accuracy: 0.9683 - val_loss: 0.2887\n",
      "Epoch 95/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.6050e-07 - val_accuracy: 0.9683 - val_loss: 0.2901\n",
      "Epoch 96/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4071e-07 - val_accuracy: 0.9683 - val_loss: 0.2915\n",
      "Epoch 97/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2284e-07 - val_accuracy: 0.9683 - val_loss: 0.2929\n",
      "Epoch 98/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.0652e-07 - val_accuracy: 0.9683 - val_loss: 0.2943\n",
      "Epoch 99/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.9074e-07 - val_accuracy: 0.9688 - val_loss: 0.2956\n",
      "Epoch 100/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.7704e-07 - val_accuracy: 0.9688 - val_loss: 0.2970\n",
      "Test Loss: 0.2622530460357666\n",
      "Test Accuracy: 0.9677000045776367\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "                    X, y,\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True\n",
    ")\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {results[0]}')\n",
    "print(f'Test Accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8551074",
   "metadata": {},
   "source": [
    "Ahora vamos a evaluar los valores en cada *epoch* de la función de perdida y la *accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss_accuracy_evolution(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist[\"epoch\"] = history.epoch \n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"loss\")\n",
    "    ax1.plot(hist['epoch'], hist['loss'], label='Train Error')\n",
    "    ax1.plot(hist['epoch'], hist['val_loss'], label = 'Val Error')\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.plot(hist['epoch'], hist['accuracy'], label='Train Accuracy')\n",
    "    ax2.plot(hist['epoch'], hist['val_accuracy'], label = 'Val Accuracy')\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_loss_accuracy_evolution(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efad91d",
   "metadata": {},
   "source": [
    "## Crear un modelo mas simple\n",
    "Una de las formas para prevenir el sobreajuste es creando un modelo más sencillo -> crear un modelo con menos numero de paramtros -> el cuál está determinado por el número de neuronas por capa.\n",
    "\n",
    "Un modelo más complejo es capaz de aprender casi cualquier cosa de los datos de entrenamiento: **INCLUSO LA ALEATORIEDAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49740cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28), name=(\"input_layer\"))\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "l_1 = layers.Dense(8, activation=\"relu\", name=\"layer_1\")(flat)\n",
    "l_2 = layers.Dense(8, activation=\"relu\", name=\"layer_2\")(l_1)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"softmax\", name=\"output_layer\")(l_2)\n",
    "\n",
    "# Definimos el modelo\n",
    "model_simpler = keras.Model(input=inputs, output=outputs, name=\"try not overfit\")\n",
    "model_simpler.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "history_simpler = model_simpler.fit(X,\n",
    "                                    y,\n",
    "                                    batch_size=64,\n",
    "                                    epochs=100,\n",
    "                                    validation_split=0.25,\n",
    "                                    shuffle=True)\n",
    "\n",
    "show_loss_accuracy_evolution(history_simpler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaaa5ab",
   "metadata": {},
   "source": [
    "## Reduciendo el `batch_size`\n",
    "Otro método es disminuyendo el tamaño del *batch* durante el *gradient descent* para así tener más incertidumbre a la hora de estimar los **parametros del gradiente**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4689fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28), name=(\"input_layer\"))\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "l_1 = layers.Dense(256, activation=\"relu\", name=\"layer_1\")(flat)\n",
    "l_2 = layers.Dense(128, activation=\"relu\", name=\"layer_2\")(l_1)\n",
    "l_3 = layers.Dense(128, activation=\"relu\", name=\"layer_3\")(l_2)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"softmax\", name=\"output_layer\")(l_3)\n",
    "\n",
    "model = keras.Model(input=inputs, output=outputs, name=\"try not overfit\")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_2 = model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=16,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True\n",
    ")\n",
    "show_loss_accuracy_evolution(history_2)\n",
    "\n",
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e071a",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Este método se aplica a una (o varias capas), y consiste en *\"dropping out\"* un número de neuronas de la capa. Para crear una capa que tenga *dropout* tendremos que usar el objeto `Dropout`.\n",
    "* `rate`: float entre [0, 1], indica la fracción de las neuronas que se van a \"dropout\"\n",
    "* `noise_shape`: \n",
    "* `seed`: semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto\n",
    "tf.keras.layers.Dropout(0.3, seed=seed)\n",
    "\n",
    "# Con functional API\n",
    "prev_layer = layers.Dense(2)\n",
    "layer = layers.Dropout(0.3, seed=seed)(prev_layer)\n",
    "\n",
    "# Con `Sequential`\n",
    "model.add(layers.Dropout(0.3, seed=seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1438a0",
   "metadata": {},
   "source": [
    "Por ello, en nuestro ejemplo nos quedará:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28), name='input_layer')\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "flat = layers.Dropout(0.5, name='dropout_flat')(flat)\n",
    "\n",
    "l_1 = layers.Dense(256, activation='relu', name='layer_1')(flat)\n",
    "l_1 = layers.Dropout(0.5, name='dropout_l1')(l_1)\n",
    "\n",
    "l_2 = layers.Dense(128, activation='relu', name='layer_2')(l_1)\n",
    "l_2 = layers.Dropout(0.5, name='dropout_l2')(l_2)\n",
    "\n",
    "l_3 = layers.Dense(128, activation='relu', name='layer_3')(l_2)\n",
    "l_3 = layers.Dropout(0.5, name='dropout_l3')(l_3)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(10, activation='softmax',\n",
    "                       name='output_layer')(l_3)\n",
    "\n",
    "\n",
    "model_dropout = keras.Model(\n",
    "    inputs=inputs, outputs=outputs, name='dont_overfit_model_dropout')\n",
    "model_dropout.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history_dropout = model_dropout.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True)\n",
    "    \n",
    "show_loss_accuracy_evolution(history_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923e269",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "`BatchNormalization` aplica una transformación que hace que la salida tenga una media cerca de 0 y una std deviation cerca de 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642948f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28), name='input_layer')\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "\n",
    "l_1 = layers.Dense(256, activation='relu', name='layer_1')(flat)\n",
    "l_1 = layers.BatchNormalization()(l_1)\n",
    "\n",
    "l_2 = layers.Dense(128, activation='relu', name='layer_2')(l_1)\n",
    "l_2 = layers.BatchNormalization()(l_2)\n",
    "\n",
    "l_3 = layers.Dense(128, activation='relu', name='layer_3')(l_2)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(10, activation='softmax',\n",
    "                       name='output_layer')(l_3)\n",
    "\n",
    "\n",
    "model_batch_norm = keras.Model(inputs=inputs, outputs=outputs, name='dont_overfit_model_batch_norm')\n",
    "model_batch_norm.summary()\n",
    "model_batch_norm.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history_batch_norm = model_batch_norm.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True)\n",
    "    \n",
    "show_loss_accuracy_evolution(history_batch_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a153eb",
   "metadata": {},
   "source": [
    "## Layer Normalization\n",
    "`LayerNormalization` es otro tipo de normalización. A diferencia de `BatchNormalization`, esto normaliza los datos a traves de todas las *features* y no depende del tamaño del *batch*, siendo así efectivo para *training* e *inferencia*.\n",
    "Calcula la media y la varianza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28), name='input_layer')\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "l_1 = layers.Dense(256, activation='relu', name='layer_1')(flat)\n",
    "l_1 = layers.LayerNormalization(axis=1)(l_1)\n",
    "\n",
    "l_2 = layers.Dense(128, activation='relu', name='layer_2')(l_1)\n",
    "l_2 = layers.LayerNormalization(axis=1)(l_2)\n",
    "\n",
    "l_3 = layers.Dense(128, activation='relu', name='layer_3')(l_2)\n",
    "\n",
    "outputs = layers.Dense(10, activation='softmax', name='output_layer')(l_3)\n",
    "\n",
    "model_layer_norm = keras.Model(inputs=inputs, outputs=outputs, name='dont_overfit_model_layer_norm')\n",
    "model_layer_norm.summary()\n",
    "model_layer_norm.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history_layer_norm = model_layer_norm.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True)\n",
    "    \n",
    "show_loss_accuracy_evolution(history_layer_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
