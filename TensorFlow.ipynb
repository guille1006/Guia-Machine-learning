{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab35684",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">TensorFlow</h1>\n",
    "<h1 style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo Díaz Aguado</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1ff55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 7777\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a49a8",
   "metadata": {},
   "source": [
    "# Tensores y variables\n",
    "TensorFlow opera en arreglos multidimensionales o **tensores** representados como objetos `tf.Tensor`.\n",
    "Tiene las caracterisiticas de:\n",
    "* `Tensor.shape`: te dice las dimensiones de estos *tensores*.\n",
    "    * ⚠️ Deben ser matrices rectangulares\n",
    "* `Tensor.dtype`: te dice el tipo de todos los elementos del *tensor. \n",
    "    * ⚠️ Todos los valores deben ser del mismo tipo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018e690",
   "metadata": {},
   "source": [
    " Estos *tensores* son *matrices multidimensionales* que ademas se comportan de una forma muy parecida a los de `nunpy`:\n",
    "\n",
    "* Con respecto a los cálculos matemáticos:\n",
    "\n",
    "| Tipo de cálculo / operación            | ¿Es similar? | NumPy (`np.ndarray`)      | TensorFlow (`tf.Tensor`)                                      | Notas                               |\n",
    "| -------------------------------------- | ------------ | ------------------------- | ------------------------------------------------------------- | ----------------------------------- |\n",
    "| **Suma de arrays/matrices**            | ✅ Sí         | `a + b`                   | `a + b`                                                       | Idéntica                            |\n",
    "| **Resta de arrays/matrices**           | ✅ Sí         | `a - b`                   | `a - b`                                                       | Idéntica                            |\n",
    "| **Multiplicación elemento a elemento** | ✅ Sí         | `a * b`                   | `a * b`                                                       | Igual                               |\n",
    "| **Producto matricial (dot product)**   | ✅ Sí         | `np.dot(a, b)`            | `tf.matmul(a, b)`                                             | Función diferente                   |\n",
    "| **Transposición**                      | ✅ Sí         | `a.T` o `np.transpose(a)` | `tf.transpose(a)`                                             | Sintaxis parecida                   |\n",
    "| **Slicing / Indexing**                 | ✅ Sí         | `a[0, :]`                 | `a[0, :]`                                                     | Idéntica                            |\n",
    "| **Broadcasting**                       | ✅ Sí         | Automático                | Automático                                                    | Muy parecido                        |\n",
    "| **Suma por ejes (axis)**               | ✅ Sí         | `np.sum(a, axis=0)`       | `tf.reduce_sum(a, axis=0)`                                    | Funciones distintas                 |\n",
    "| **Mean / promedio**                    | ✅ Sí         | `np.mean(a)`              | `tf.reduce_mean(a)`                                           | Diferente nombre                    |\n",
    "| **Varianza / desviación típica**       | ✅ Sí         | `np.var(a)`               | `tf.math.reduce_variance(a)`                                  | TF usa `tf.math`                    |\n",
    "| **Funciones trigonométricas**          | ✅ Sí         | `np.sin(a)`               | `tf.math.sin(a)`                                              | Misma lógica                        |\n",
    "| **Funciones log, exp, sqrt, etc.**     | ✅ Sí         | `np.log(a)`               | `tf.math.log(a)`                                              | Prefijo `math.`                     |\n",
    "| **Reshape / cambio de forma**          | ✅ Sí         | `a.reshape((2, 4))`       | `tf.reshape(a, (2, 4))`                                       | Igual                               |\n",
    "| **Stack / concat / split**             | ✅ Sí         | `np.concatenate([...])`   | `tf.concat([...])`                                            | Igual lógica                        |\n",
    "| **Argmax / argmin**                    | ✅ Sí         | `np.argmax(a)`            | `tf.argmax(a)`                                                | Igual                               |\n",
    "| **Sort / argsort**                     | ✅ Sí         | `np.sort(a)`              | `tf.sort(a)`                                                  | Igual                               |\n",
    "| **Boolean masking / filtrado**         | ✅ Sí         | `a[a > 0]`                | `tf.boolean_mask(a, a > 0)`                                   | Similar pero con función específica |\n",
    "| **Operaciones en GPU**                 | ❌ No         | ❌ No                      | ✅ Sí (automático)                                             | Gran diferencia                     |\n",
    "| **Autodiferenciación (gradientes)**    | ❌ No         | ❌ No                      | ✅ Sí (`tf.GradientTape`)                                      | Solo TF                             |\n",
    "| **Ejecución simbólica / gráfica**      | ❌ No         | ❌ No                      | ✅ Sí (modo gráfico o eager)                                   | Solo TF                             |\n",
    "| **Mutabilidad (modificar valores)**    | ❌ No         | ✅ Sí (`a[0,0] = 5`)       | ❌ No (`tf.Tensor` es inmutable)                               | Solo mutable en NumPy               |\n",
    "| **Conversión a lista**                 | ✅ Sí         | `a.tolist()`              | `a.numpy().tolist()`                                          | En TF necesitas `.numpy()` primero  |\n",
    "| **Guardar en disco (formato nativo)**  | ✅ Similar    | `np.save()` / `np.load()` | `tf.saved_model` (modelos), o `.numpy()` para exportar arrays | Diferente enfoque                   |\n",
    "\n",
    "Y con respecto a sus caracteristicas:\n",
    "\n",
    "| Característica                   | **NumPy array**            | **TensorFlow tensor**                         |\n",
    "| -------------------------------- | -------------------------- | --------------------------------------------- |\n",
    "| Tipo                             | `numpy.ndarray`            | `tf.Tensor`                                   |\n",
    "| Biblioteca                       | NumPy                      | TensorFlow                                    |\n",
    "| Uso principal                    | Cálculo científico general | Computación automática (ML/DL)                |\n",
    "| Soporte para GPU                 | ❌ No (solo CPU)            | ✅ Sí (GPU, TPU, CPU)                          |\n",
    "| Diferenciación automática        | ❌ No                       | ✅ Sí (con `tf.GradientTape`)                  |\n",
    "| Computación simbólica            | ❌ No                       | ✅ Sí (gráficos computacionales)               |\n",
    "| Inmutabilidad                    | ✅ Mutable                  | ⚠️ Inmutable (no puedes cambiar su contenido) |\n",
    "| Integración con redes neuronales | ❌ No directo               | ✅ Nativo (keras, optimizers, etc.)            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e9e4c",
   "metadata": {},
   "source": [
    "## Tensor constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f603babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "()\n",
      "tf.Tensor([17 12], shape=(2,), dtype=int32)\n",
      "(2,)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = tf.constant(18)\n",
    "print(scalar)\n",
    "print(scalar.shape)\n",
    "\n",
    "# Vector\n",
    "vector = tf.constant([17, 12])\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "\n",
    "# Matrices\n",
    "matrix = tf.constant([[1, 2],\n",
    "                      [3, 4]])\n",
    "print(matrix)\n",
    "print(matrix.shape)\n",
    "\n",
    "# Tensor\n",
    "tensor = tf.constant([[[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8e03b",
   "metadata": {},
   "source": [
    "# First Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e782d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8a305",
   "metadata": {},
   "source": [
    "## Input\n",
    "Para definir la usamos el objeto `Input`. Debe ser el numero de variables independientes.\n",
    "* `shape`: dimensión de entrada, tiene que estar en el formato de (input_dimension,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9e155",
   "metadata": {},
   "source": [
    "## Dense\n",
    "Podemos crear capas *completamente conectadas* usando la clase `Dense`. \n",
    "Tiene lso siguientes parametros:\n",
    "* `units`: Número de neuronas en esa capa.\n",
    "* `activation`: Función de activación que usaremos. Por defecto está la función *lineal* .\n",
    "* `name`: Es interesante poner el nombre de cada capa para poder identificarlas.\n",
    "* `input_shape`: En caso de no querer usar el objeto `Input`, podemos incluir una primera capa que tenga este atributo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8151fb",
   "metadata": {},
   "source": [
    "## Sequential\n",
    "El objeto `Sequential` <u> es donde vamos a crear nuestra red neuronal </u>. Tenemos dos formas para crearlo:\n",
    "1. * Crear el objeto\n",
    "    * Vamos añadiendo las capas con el método **.add** a nuestro objeto\n",
    "    * Recordar que la primera capa debe ser `Input` o `Dense`(con el atributo de *input_shape*)\n",
    "2. * Podemos guardar directamente el modelo con todas las capas guardadas en una lista.\n",
    "    * Además también se pueden añadir más capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ed9daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.Sequential()\n",
    "model1.add(layers.Dense(3, activation=\"sigmoid\", name=\"input_lay\", input_shape=(2,)))\n",
    "model1.add(layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\"))\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    keras.Input(shape=(2,)),\n",
    "    layers.Dense(3, activation=\"sigmoid\", name=\"input_layer\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985f6bd",
   "metadata": {},
   "source": [
    "# Guardar y cargar modelos de Keras\n",
    "## Guardar modelo\n",
    "Puedes guardar facilmente tu modelo entero (arquitectura, pesos, optimizer state) usando el método `save` y ponemos el nombre del archivo que lo queremos guardar, importante poner el sufijo \".keras\" o \".h5\".\n",
    "* .keras: El modo recomnedado y por defecto para TenserFlow 2.12. Incluye metadata del modelo y es \"future-proof\".\n",
    "* .h5: Es muy usado y es muy simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb62abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model1.save(\"Modelo_Keras.keras\")\n",
    "model1.save(\"Modelo2_Keras.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb8eaf",
   "metadata": {},
   "source": [
    "## Cargar un modelo. \n",
    "Simplemente debemos llamar a la funcion `load_model` y escribir el nombre del archivo donde esté guardado el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7c19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "modelo_cargado = load_model(\"Modelo_Keras.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6dd7fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd456c9",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740424bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "seed = 7777\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc8c841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargo el datset\n",
    "mnist = tf.keras.datasets.mnist   \n",
    "\n",
    "# Pongo los valores de train y test\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Como son valores de 0 a 255 puedo normalizarlo dividiendo entre 255\n",
    "X_train, X_test = X_train/255.0, X_test/255.0\n",
    "\n",
    "i_rand = np.random.randint(0, len(X_train))\n",
    "plt.imshow(X_train[i_rand])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b153b9",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer más pequeño nuestro dataset de test para que tengamos aun mas **OVERFITTING**.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b4a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, X, _, y = train_test_split(X_train, y_train, test_size=0.2, random_state=seed, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5261aa6",
   "metadata": {},
   "source": [
    "## Creación del modelo\n",
    "Vamos a crear un modelo que sea capaz de generalizar. Nuestro modelo consistirá en :\n",
    "* Input de dimensión 28,28\n",
    "* Capa de flatten (para así tener los datos en una lista)\n",
    "* 3 Dense hidden layer \n",
    "* Output layer con una sola neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a597e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"try_not_overfit\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"try_not_overfit\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,497</span> (978.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,497\u001b[0m (978.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,497</span> (978.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m250,497\u001b[0m (978.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28), name=(\"input_layer\"))\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "l_1 = layers.Dense(256, activation=\"relu\", name=\"layer_1\")(flat)\n",
    "l_2 = layers.Dense(128, activation=\"relu\", name=\"layer_2\")(l_1)\n",
    "l_3 = layers.Dense(128, activation=\"relu\", name=\"layer_3\")(l_2)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"softmax\", name=\"output_layer\")(l_3)\n",
    "\n",
    "# Definimos el modelo\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"try_not_overfit\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff2ba6",
   "metadata": {},
   "source": [
    "Ahora usaremos la siguiente configuración para entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21e29795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py:908: UserWarning: You are using a softmax over axis -1 of a tensor of shape (64, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'try not overfit_layer_1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      2\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'try not overfit_layer_1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "                    X, y,\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True\n",
    ")\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {results[0]}')\n",
    "print(f'Test Accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8551074",
   "metadata": {},
   "source": [
    "Ahora vamos a evaluar los valores en cada *epoch* de la función de perdida y la *accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss_accuracy_evolution(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist[\"epoch\"] = history.epoch \n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"loss\")\n",
    "    ax1.plot(hist['epoch'], hist['loss'], label='Train Error')\n",
    "    ax1.plot(hist['epoch'], hist['val_loss'], label = 'Val Error')\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.plot(hist['epoch'], hist['accuracy'], label='Train Accuracy')\n",
    "    ax2.plot(hist['epoch'], hist['val_accuracy'], label = 'Val Accuracy')\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_loss_accuracy_evolution(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efad91d",
   "metadata": {},
   "source": [
    "## Crear un modelo mas simple\n",
    "Una de las formas para prevenir el sobreajuste es creando un modelo más sencillo -> crear un modelo con menos numero de paramtros -> el cuál está determinado por el número de neuronas por capa.\n",
    "\n",
    "Un modelo más complejo es capaz de aprender casi cualquier cosa de los datos de entrenamiento: **INCLUSO LA ALEATORIEDAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49740cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28), name=(\"input_layer\"))\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "l_1 = layers.Dense(8, activation=\"relu\", name=\"layer_1\")(flat)\n",
    "l_2 = layers.Dense(8, activation=\"relu\", name=\"layer_2\")(l_1)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"softmax\", name=\"output_layer\")(l_2)\n",
    "\n",
    "# Definimos el modelo\n",
    "model_simpler = keras.Model(input=inputs, output=outputs, name=\"try not overfit\")\n",
    "model_simpler.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "history_simpler = model_simpler.fit(X,\n",
    "                                    y,\n",
    "                                    batch_size=64,\n",
    "                                    epochs=100,\n",
    "                                    validation_split=0.25,\n",
    "                                    shuffle=True)\n",
    "\n",
    "show_loss_accuracy_evolution(history_simpler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaaa5ab",
   "metadata": {},
   "source": [
    "## Reduciendo el `batch_size`\n",
    "Otro método es disminuyendo el tamaño del *batch* durante el *gradient descent* para así tener más incertidumbre a la hora de estimar los **parametros del gradiente**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4689fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28), name=(\"input_layer\"))\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "l_1 = layers.Dense(256, activation=\"relu\", name=\"layer_1\")(flat)\n",
    "l_2 = layers.Dense(128, activation=\"relu\", name=\"layer_2\")(l_1)\n",
    "l_3 = layers.Dense(128, activation=\"relu\", name=\"layer_3\")(l_2)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"softmax\", name=\"output_layer\")(l_3)\n",
    "\n",
    "model = keras.Model(input=inputs, output=outputs, name=\"try not overfit\")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_2 = model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=16,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True\n",
    ")\n",
    "show_loss_accuracy_evolution(history_2)\n",
    "\n",
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e071a",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Este método se aplica a una (o varias capas), y consiste en *\"dropping out\"* un número de neuronas de la capa. Para crear una capa que tenga *dropout* tendremos que usar el objeto `Dropout`.\n",
    "* `rate`: float entre [0, 1], indica la fracción de las neuronas que se van a \"dropout\"\n",
    "* `noise_shape`: \n",
    "* `seed`: semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto\n",
    "tf.keras.layers.Dropout(0.3, seed=seed)\n",
    "\n",
    "# Con functional API\n",
    "prev_layer = layers.Dense(2)\n",
    "layer = layers.Dropout(0.3, seed=seed)(prev_layer)\n",
    "\n",
    "# Con `Sequential`\n",
    "model.add(layers.Dropout(0.3, seed=seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1438a0",
   "metadata": {},
   "source": [
    "Por ello, en nuestro ejemplo nos quedará:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28), name='input_layer')\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "flat = layers.Dropout(0.5, name='dropout_flat')(flat)\n",
    "\n",
    "l_1 = layers.Dense(256, activation='relu', name='layer_1')(flat)\n",
    "l_1 = layers.Dropout(0.5, name='dropout_l1')(l_1)\n",
    "\n",
    "l_2 = layers.Dense(128, activation='relu', name='layer_2')(l_1)\n",
    "l_2 = layers.Dropout(0.5, name='dropout_l2')(l_2)\n",
    "\n",
    "l_3 = layers.Dense(128, activation='relu', name='layer_3')(l_2)\n",
    "l_3 = layers.Dropout(0.5, name='dropout_l3')(l_3)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(10, activation='softmax',\n",
    "                       name='output_layer')(l_3)\n",
    "\n",
    "\n",
    "model_dropout = keras.Model(\n",
    "    inputs=inputs, outputs=outputs, name='dont_overfit_model_dropout')\n",
    "model_dropout.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history_dropout = model_dropout.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True)\n",
    "    \n",
    "show_loss_accuracy_evolution(history_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923e269",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "`BatchNormalization` aplica una transformación que hace que la salida tenga una media cerca de 0 y una std deviation cerca de 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642948f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28), name='input_layer')\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "\n",
    "l_1 = layers.Dense(256, activation='relu', name='layer_1')(flat)\n",
    "l_1 = layers.BatchNormalization()(l_1)\n",
    "\n",
    "l_2 = layers.Dense(128, activation='relu', name='layer_2')(l_1)\n",
    "l_2 = layers.BatchNormalization()(l_2)\n",
    "\n",
    "l_3 = layers.Dense(128, activation='relu', name='layer_3')(l_2)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(10, activation='softmax',\n",
    "                       name='output_layer')(l_3)\n",
    "\n",
    "\n",
    "model_batch_norm = keras.Model(inputs=inputs, outputs=outputs, name='dont_overfit_model_batch_norm')\n",
    "model_batch_norm.summary()\n",
    "model_batch_norm.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history_batch_norm = model_batch_norm.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True)\n",
    "    \n",
    "show_loss_accuracy_evolution(history_batch_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a153eb",
   "metadata": {},
   "source": [
    "## Layer Normalization\n",
    "`LayerNormalization` es otro tipo de normalización. A diferencia de `BatchNormalization`, esto normaliza los datos a traves de todas las *features* y no depende del tamaño del *batch*, siendo así efectivo para *training* e *inferencia*.\n",
    "Calcula la media y la varianza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28), name='input_layer')\n",
    "\n",
    "flat = layers.Flatten()(inputs)\n",
    "\n",
    "l_1 = layers.Dense(256, activation='relu', name='layer_1')(flat)\n",
    "l_1 = layers.LayerNormalization(axis=1)(l_1)\n",
    "\n",
    "l_2 = layers.Dense(128, activation='relu', name='layer_2')(l_1)\n",
    "l_2 = layers.LayerNormalization(axis=1)(l_2)\n",
    "\n",
    "l_3 = layers.Dense(128, activation='relu', name='layer_3')(l_2)\n",
    "\n",
    "outputs = layers.Dense(10, activation='softmax', name='output_layer')(l_3)\n",
    "\n",
    "model_layer_norm = keras.Model(inputs=inputs, outputs=outputs, name='dont_overfit_model_layer_norm')\n",
    "model_layer_norm.summary()\n",
    "model_layer_norm.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history_layer_norm = model_layer_norm.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True)\n",
    "    \n",
    "show_loss_accuracy_evolution(history_layer_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
