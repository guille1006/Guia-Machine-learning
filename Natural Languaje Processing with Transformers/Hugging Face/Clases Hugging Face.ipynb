{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62034f7",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 3em; font-weight: bold; text-align: center;\">Clases en Hugging Face</div>\n",
    "<div style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo Díaz Aguado</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a8511b",
   "metadata": {},
   "source": [
    "# Resumen general de todas las librerias y clases\n",
    "* [Datasets](#libreria-datasets): Librería de HuggingFace que nos permite descargar datasets de su Hub y también subir nuestros propios datasets.\n",
    "\n",
    "* [Transformers](#libreria-transformers): Libreria de Hugging Face que proporciona miles de modelos preentrenados para una variedad de tareas de NLP, como traducción, resumen, clasificación de texto y generación de texto.\n",
    "    * [`Pipelines`](#pipelines): Clase donde lo único que te tienes que preocupar es de indicar es en la tarea especifica que va a desarrollar.\n",
    "    * [`AutoClasses`](#autoclasses): No es una clase, es un concepto que sirve para englobar todos los `Auto` de Hugging Face.\n",
    "        * [`AutoTokenizer`](#autotokenizer): Clase que carga el **tokenizador** adecuado según el modelo que estes usando.\n",
    "        * [`AutoModel`](#automodel): Clase que carga el **modelo** de cualquier arquitectura.\n",
    "        * [`AutoFeatureExtractor`](#autofeatureextractor): Clase que sirve para cargar automáticamente el **extractor de características** adecuado para modelos *no basados en texto*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dba42",
   "metadata": {},
   "source": [
    "# Libreria Datasets\n",
    "Librería de HuggingFace que nos permite descargar datasets de su Hub y también subir nuestros propios datasets.\n",
    "\n",
    "* Está optimizada para ser eficiente en memoria y rendimiento.\n",
    "* Está diseñada para manejar grandes conjuntos de datos que podrían no caber en la memoria RAM de manera eficiente.\n",
    "* Contiene funciones integradas para el preprocesamiento y la transformación de variables.\n",
    "* No solo para textos, también Audios e Imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46a9b8",
   "metadata": {},
   "source": [
    "# Libreria Transformers\n",
    "Libreria de Hugging Face que proporciona miles de modelos preentrenados para una variedad de tareas de NLP, como traducción, resumen, clasificación de texto y generación de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c78d2d",
   "metadata": {},
   "source": [
    "## `Pipelines`\n",
    "Clase donde lo único que te tienes que preocupar es de indicar es en la tarea especifica que va a desarrollar. \n",
    "\n",
    "Elige los siguientes elementos automaticamente:\n",
    "* Preprocesador\n",
    "    * Tokenizador\n",
    "* Modelo preentrenado\n",
    "* Postprocesamiento del resultado\n",
    "\n",
    "La abstracción `pipeline` es un *wrapper* donde están todos los posibles **Task-specific pipelines**. Por ello es importante destacar que cada **tarea** realiza operaciones distintas dentro del `Pipeline`, así que tendrá distintos para cada tarea. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d290b",
   "metadata": {},
   "source": [
    "\n",
    "### Pipelines Funcionamiento\n",
    "Lo primero es inicializar el objeto que queramos usar incluyendo elementos claves como pueden ser:\n",
    "* `task`, `model` o ambos. Así indicaremos que tipo de proceso se llevará a cabo\n",
    "\n",
    "### Pipelines Parameters\n",
    "\n",
    "#### `task` (`str`)\n",
    "Define qué tipo de *pipeline* se devolverá. Las tareas aceptadas actualmente son:\n",
    "\n",
    "- `\"audio-classification\"` → `AudioClassificationPipeline`\n",
    "- `\"automatic-speech-recognition\"` → `AutomaticSpeechRecognitionPipeline`\n",
    "- `\"depth-estimation\"` → `DepthEstimationPipeline`\n",
    "- `\"document-question-answering\"` → `DocumentQuestionAnsweringPipeline`\n",
    "- `\"feature-extraction\"` → `FeatureExtractionPipeline`\n",
    "- `\"fill-mask\"` → `FillMaskPipeline`\n",
    "- `\"image-classification\"` → `ImageClassificationPipeline`\n",
    "- `\"image-feature-extraction\"` → `ImageFeatureExtractionPipeline`\n",
    "- `\"image-segmentation\"` → `ImageSegmentationPipeline`\n",
    "- `\"image-text-to-text\"` → `ImageTextToTextPipeline`\n",
    "- `\"image-to-image\"` → `ImageToImagePipeline`\n",
    "- `\"image-to-text\"` → `ImageToTextPipeline`\n",
    "- `\"mask-generation\"` → `MaskGenerationPipeline`\n",
    "- `\"object-detection\"` → `ObjectDetectionPipeline`\n",
    "- `\"question-answering\"` → `QuestionAnsweringPipeline`\n",
    "- `\"summarization\"` → `SummarizationPipeline`\n",
    "- `\"table-question-answering\"` → `TableQuestionAnsweringPipeline`\n",
    "- `\"text2text-generation\"` → `Text2TextGenerationPipeline`\n",
    "- `\"text-classification\"` (alias `\"sentiment-analysis\"`) → `TextClassificationPipeline`\n",
    "- `\"text-generation\"` → `TextGenerationPipeline`\n",
    "- `\"text-to-audio\"` (alias `\"text-to-speech\"`) → `TextToAudioPipeline`\n",
    "- `\"token-classification\"` (alias `\"ner\"`) → `TokenClassificationPipeline`\n",
    "- `\"translation\"` → `TranslationPipeline`\n",
    "- `\"translation_xx_to_yy\"` → `TranslationPipeline`\n",
    "- `\"video-classification\"` → `VideoClassificationPipeline`\n",
    "- `\"visual-question-answering\"` → `VisualQuestionAnsweringPipeline`\n",
    "- `\"zero-shot-classification\"` → `ZeroShotClassificationPipeline`\n",
    "- `\"zero-shot-image-classification\"` → `ZeroShotImageClassificationPipeline`\n",
    "- `\"zero-shot-audio-classification\"` → `ZeroShotAudioClassificationPipeline`\n",
    "- `\"zero-shot-object-detection\"` → `ZeroShotObjectDetectionPipeline`\n",
    "\n",
    "---\n",
    "\n",
    "#### `model` (`str` | `PreTrainedModel` | `TFPreTrainedModel`, *optional*)\n",
    "El modelo que usará el pipeline. Puede ser un identificador de modelo o una instancia de un modelo preentrenado.  \n",
    "Si no se proporciona, se usará el modelo por defecto para la tarea.\n",
    "\n",
    "---\n",
    "\n",
    "#### `config` (`str` | `PretrainedConfig`, *optional*)\n",
    "Configuración usada para instanciar el modelo.  \n",
    "Si no se proporciona, se usará la configuración por defecto del modelo dado o de la tarea.\n",
    "\n",
    "---\n",
    "\n",
    "#### `tokenizer` (`str` | `PreTrainedTokenizer`, *optional*)\n",
    "Tokenizador que codificará los datos para el modelo.  \n",
    "Si no se proporciona, se cargará el tokenizador por defecto para el modelo, la configuración o la tarea.\n",
    "\n",
    "---\n",
    "\n",
    "#### `feature_extractor` (`str` | `PreTrainedFeatureExtractor`, *optional*)\n",
    "Extractor de características usado para modelos no NLP (visión, audio o multi-modal).  \n",
    "Si no se proporciona, se carga el extractor por defecto según el modelo o la tarea.\n",
    "\n",
    "---\n",
    "\n",
    "#### `image_processor` (`str` | `BaseImageProcessor`, *optional*)\n",
    "Procesador de imágenes para modelos de visión o multimodales.  \n",
    "Si no se proporciona, se cargará el procesador por defecto.\n",
    "\n",
    "---\n",
    "\n",
    "#### `processor` (`str` | `ProcessorMixin`, *optional*)\n",
    "Procesador para entradas multimodales (texto + imagen, por ejemplo).  \n",
    "Se carga el por defecto si no se proporciona.\n",
    "\n",
    "---\n",
    "\n",
    "#### `framework` (`str`, *optional*)\n",
    "Framework a usar: `\"pt\"` (PyTorch) o `\"tf\"` (TensorFlow).  \n",
    "Si no se especifica, se elige automáticamente según lo instalado o el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "#### `revision` (`str`, *optional*, por defecto `\"main\"`)\n",
    "Revisión específica del modelo (rama, tag o commit) en Hugging Face Hub.\n",
    "\n",
    "---\n",
    "\n",
    "#### `use_fast` (`bool`, *optional*, por defecto `True`)\n",
    "Usar un tokenizer rápido (`PreTrainedTokenizerFast`) si está disponible.\n",
    "\n",
    "---\n",
    "\n",
    "#### `use_auth_token` (`str` | `bool`, *optional*)\n",
    "Token de autenticación para acceder a archivos privados del Hub.  \n",
    "Si es `True`, usará el token generado con `huggingface-cli login`.\n",
    "\n",
    "---\n",
    "\n",
    "#### `device` (`int` | `str` | `torch.device`)\n",
    "Dispositivo donde se ejecutará el pipeline (`\"cpu\"`, `\"cuda\"`, `\"mps\"`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "#### `device_map` (`str` | `dict`, *optional*)\n",
    "Distribución automática de modelos entre dispositivos (usando `accelerate`).  \n",
    "**⚠️ No usar junto con `device`, ya que entran en conflicto.**\n",
    "\n",
    "---\n",
    "\n",
    "#### `torch_dtype` (`str` | `torch.dtype`, *optional*)\n",
    "Precisión usada en PyTorch (`float16`, `bfloat16`, `\"auto\"`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "#### `trust_remote_code` (`bool`, *optional*, por defecto `False`)\n",
    "Permite ejecutar código personalizado de los repositorios.  \n",
    "**⚠️ Solo usar si confías en el código.**\n",
    "\n",
    "---\n",
    "\n",
    "#### `model_kwargs` (`dict`, *optional*)\n",
    "Argumentos adicionales enviados al cargar el modelo con `from_pretrained()`.\n",
    "\n",
    "---\n",
    "\n",
    "#### `kwargs` (`dict`, *optional*)\n",
    "Argumentos adicionales pasados al inicializar el pipeline específico.\n",
    "\n",
    "---\n",
    "\n",
    "### Pipelines Returns\n",
    "\n",
    "#### `Pipeline`\n",
    "Devuelve un objeto pipeline adecuado para la tarea especificada.\n",
    "\n",
    "\n",
    "### Pipeline Batching\n",
    "\n",
    "Todas las *pipelines* pueden usar *batching* peor tienes que darles algun objeto divisible -> List, Dataset, generator\n",
    "\n",
    "#### Pipeline Chunk Batching\n",
    "\n",
    "Existen casos como `zero-shot.classification` y `question-answering` que no es posible hacer la división de batches como quisieramos hacer de forma normal puesto que los datos de uno se utilizan para otro. Para ello hacemos:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89615b76",
   "metadata": {},
   "source": [
    "## Autoclasses\n",
    "Muchas veces, la arquitectura que queremos usar seguramente esté en un *modelo preentrenado* al que podemos acceder usando el método `from_pretrained()`\n",
    "\n",
    "Es importante recordar que debemos usar el método `from_pretrained()` para indicarle que modelo estamos usando para todas las siguientes clases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88321621",
   "metadata": {},
   "source": [
    "### `AutoTokenizer`\n",
    "Sirve para cargar el **tokenizador** adecuado según el modelo que estés usando. No hace falta que tu sepas cual hay que usar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b95a2f0",
   "metadata": {},
   "source": [
    "### `Automodel`\n",
    "Es una clase que carga el **modelo base** de cualquier arquitectura soportada. \n",
    "\n",
    "El **modelo base** es:\n",
    "* El modelo **sin cabeza(head)** especifica para tareas\n",
    "* Solo incluye las capas fundamentales que generan las representaciones internas:\n",
    "    * **embeddings**\n",
    "    * **transformaciones internas**\n",
    "    * **hidden states**\n",
    "\n",
    "#### Función exacta de `Automodel`\n",
    "1. <u>Detecta el modelo correcto a partir del identificador </u> que le pases (por ejemplo \"bert-base-uncased\") y carga automáticamente la clase que corresponde (`BertModel`)\n",
    "2. <u>Carga los pesos preentrenados </u> del modelo base correspondiente.\n",
    "3. Ejecuta el modelo\n",
    "\n",
    "#### Salida de `Automodel`\n",
    "* `last_hidden_state`: tensor con la representación final de la última capa con la forma -> [batch_size, seq_len, hidden_dim]\n",
    "* Si activas `output_hidden_states=True` obtienes también:\n",
    "    * `hidden_states`: tupla con la salida de cada capa del modelo\n",
    "* Si activas `output_attentions=True`\n",
    "    * Obtienes matrices de las *attention* internas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c743e3",
   "metadata": {},
   "source": [
    "### `AutoFeatureExtractor`\n",
    "Sirve para cargar automáticamente el **extractor de características** adecuado para modelos *no basados en texto*.\n",
    "\n",
    "#### Adjunto \n",
    "En modelos recientes, esta clase está siendo reemplazada por `AutoImageProcessor` y `AutoProcessor`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca690693",
   "metadata": {},
   "source": [
    "## `TrainingArguments`\n",
    "La clase `TrainingArguments` contendrá todos los **hiperparámetros** que luego la clase `Trainer` usará para el entrenamiento y la evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116c464",
   "metadata": {},
   "source": [
    "## `Trainer`\n",
    "Esta clase automatiza muchos pasos del ciclo de entrenamientos, que de otra manera, tendrias que hacerlo manualmente usando Pytorch o TensorFlow. Sus funciones principales son:\n",
    "1. Entrenamiento.   \n",
    "    Llama al método `.train()` del modelo con el dataset de entrenamiento *train_dataset*. Aplica:\n",
    "    * Optimización\n",
    "    * Backpropagation\n",
    "    * Cálculo de pérdida\n",
    "    * ...\n",
    "2. Evaluación.  \n",
    "    Evalua el modelo con el dataset de valuación *eval_dataset*. \n",
    "3. Predicción.  \n",
    "    Hace inferencia sobre datos no etiquetados. \n",
    "4. Gestión automatica de:  \n",
    "    * Tonkenización (si pasas el tokenizer)\n",
    "    * Parametros de "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96369b06",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
