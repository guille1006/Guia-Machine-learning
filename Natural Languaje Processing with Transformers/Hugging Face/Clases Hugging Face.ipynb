{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62034f7",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 3em; font-weight: bold; text-align: center;\">Clases en Hugging Face</div>\n",
    "<div style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo D√≠az Aguado</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2899ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c78d2d",
   "metadata": {},
   "source": [
    "## `Pipelines`\n",
    "En ü§ó Hugging Face, los pipelines son una forma muy sencilla y directa de usar modelos preentrenados para tareas comunes de procesamiento de lenguaje natural, visi√≥n, audio y m√°s, sin preocuparte por los detalles internos de tokenizaci√≥n, preprocesamiento o inferencia\n",
    "\n",
    "Combina:\n",
    "* Preprocesador\n",
    "    * Tokenizador\n",
    "* Modelo preentrenado\n",
    "* Postprocesamiento del resultado\n",
    "\n",
    "La abstracci√≥n `pipeline` es un *wrapper* donde est√°n todos los posibles **Task-specific pipelines**\n",
    "\n",
    "### Pipelines Funcionamiento\n",
    "Lo primero es inicializar el objeto que queramos usar incluyendo elementos claves como pueden ser:\n",
    "* `task`, `model` o ambos. As√≠ indicaremos que tipo de proceso se llevar√° a cabo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36fcea6",
   "metadata": {},
   "source": [
    "### Pipelines Parameters\n",
    "\n",
    "#### `task` (`str`)\n",
    "Define qu√© tipo de *pipeline* se devolver√°. Las tareas aceptadas actualmente son:\n",
    "\n",
    "- `\"audio-classification\"` ‚Üí `AudioClassificationPipeline`\n",
    "- `\"automatic-speech-recognition\"` ‚Üí `AutomaticSpeechRecognitionPipeline`\n",
    "- `\"depth-estimation\"` ‚Üí `DepthEstimationPipeline`\n",
    "- `\"document-question-answering\"` ‚Üí `DocumentQuestionAnsweringPipeline`\n",
    "- `\"feature-extraction\"` ‚Üí `FeatureExtractionPipeline`\n",
    "- `\"fill-mask\"` ‚Üí `FillMaskPipeline`\n",
    "- `\"image-classification\"` ‚Üí `ImageClassificationPipeline`\n",
    "- `\"image-feature-extraction\"` ‚Üí `ImageFeatureExtractionPipeline`\n",
    "- `\"image-segmentation\"` ‚Üí `ImageSegmentationPipeline`\n",
    "- `\"image-text-to-text\"` ‚Üí `ImageTextToTextPipeline`\n",
    "- `\"image-to-image\"` ‚Üí `ImageToImagePipeline`\n",
    "- `\"image-to-text\"` ‚Üí `ImageToTextPipeline`\n",
    "- `\"mask-generation\"` ‚Üí `MaskGenerationPipeline`\n",
    "- `\"object-detection\"` ‚Üí `ObjectDetectionPipeline`\n",
    "- `\"question-answering\"` ‚Üí `QuestionAnsweringPipeline`\n",
    "- `\"summarization\"` ‚Üí `SummarizationPipeline`\n",
    "- `\"table-question-answering\"` ‚Üí `TableQuestionAnsweringPipeline`\n",
    "- `\"text2text-generation\"` ‚Üí `Text2TextGenerationPipeline`\n",
    "- `\"text-classification\"` (alias `\"sentiment-analysis\"`) ‚Üí `TextClassificationPipeline`\n",
    "- `\"text-generation\"` ‚Üí `TextGenerationPipeline`\n",
    "- `\"text-to-audio\"` (alias `\"text-to-speech\"`) ‚Üí `TextToAudioPipeline`\n",
    "- `\"token-classification\"` (alias `\"ner\"`) ‚Üí `TokenClassificationPipeline`\n",
    "- `\"translation\"` ‚Üí `TranslationPipeline`\n",
    "- `\"translation_xx_to_yy\"` ‚Üí `TranslationPipeline`\n",
    "- `\"video-classification\"` ‚Üí `VideoClassificationPipeline`\n",
    "- `\"visual-question-answering\"` ‚Üí `VisualQuestionAnsweringPipeline`\n",
    "- `\"zero-shot-classification\"` ‚Üí `ZeroShotClassificationPipeline`\n",
    "- `\"zero-shot-image-classification\"` ‚Üí `ZeroShotImageClassificationPipeline`\n",
    "- `\"zero-shot-audio-classification\"` ‚Üí `ZeroShotAudioClassificationPipeline`\n",
    "- `\"zero-shot-object-detection\"` ‚Üí `ZeroShotObjectDetectionPipeline`\n",
    "\n",
    "---\n",
    "\n",
    "#### `model` (`str` | `PreTrainedModel` | `TFPreTrainedModel`, *optional*)\n",
    "El modelo que usar√° el pipeline. Puede ser un identificador de modelo o una instancia de un modelo preentrenado.  \n",
    "Si no se proporciona, se usar√° el modelo por defecto para la tarea.\n",
    "\n",
    "---\n",
    "\n",
    "#### `config` (`str` | `PretrainedConfig`, *optional*)\n",
    "Configuraci√≥n usada para instanciar el modelo.  \n",
    "Si no se proporciona, se usar√° la configuraci√≥n por defecto del modelo dado o de la tarea.\n",
    "\n",
    "---\n",
    "\n",
    "#### `tokenizer` (`str` | `PreTrainedTokenizer`, *optional*)\n",
    "Tokenizador que codificar√° los datos para el modelo.  \n",
    "Si no se proporciona, se cargar√° el tokenizador por defecto para el modelo, la configuraci√≥n o la tarea.\n",
    "\n",
    "---\n",
    "\n",
    "#### `feature_extractor` (`str` | `PreTrainedFeatureExtractor`, *optional*)\n",
    "Extractor de caracter√≠sticas usado para modelos no NLP (visi√≥n, audio o multi-modal).  \n",
    "Si no se proporciona, se carga el extractor por defecto seg√∫n el modelo o la tarea.\n",
    "\n",
    "---\n",
    "\n",
    "#### `image_processor` (`str` | `BaseImageProcessor`, *optional*)\n",
    "Procesador de im√°genes para modelos de visi√≥n o multimodales.  \n",
    "Si no se proporciona, se cargar√° el procesador por defecto.\n",
    "\n",
    "---\n",
    "\n",
    "#### `processor` (`str` | `ProcessorMixin`, *optional*)\n",
    "Procesador para entradas multimodales (texto + imagen, por ejemplo).  \n",
    "Se carga el por defecto si no se proporciona.\n",
    "\n",
    "---\n",
    "\n",
    "#### `framework` (`str`, *optional*)\n",
    "Framework a usar: `\"pt\"` (PyTorch) o `\"tf\"` (TensorFlow).  \n",
    "Si no se especifica, se elige autom√°ticamente seg√∫n lo instalado o el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "#### `revision` (`str`, *optional*, por defecto `\"main\"`)\n",
    "Revisi√≥n espec√≠fica del modelo (rama, tag o commit) en Hugging Face Hub.\n",
    "\n",
    "---\n",
    "\n",
    "#### `use_fast` (`bool`, *optional*, por defecto `True`)\n",
    "Usar un tokenizer r√°pido (`PreTrainedTokenizerFast`) si est√° disponible.\n",
    "\n",
    "---\n",
    "\n",
    "#### `use_auth_token` (`str` | `bool`, *optional*)\n",
    "Token de autenticaci√≥n para acceder a archivos privados del Hub.  \n",
    "Si es `True`, usar√° el token generado con `huggingface-cli login`.\n",
    "\n",
    "---\n",
    "\n",
    "#### `device` (`int` | `str` | `torch.device`)\n",
    "Dispositivo donde se ejecutar√° el pipeline (`\"cpu\"`, `\"cuda\"`, `\"mps\"`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "#### `device_map` (`str` | `dict`, *optional*)\n",
    "Distribuci√≥n autom√°tica de modelos entre dispositivos (usando `accelerate`).  \n",
    "**‚ö†Ô∏è No usar junto con `device`, ya que entran en conflicto.**\n",
    "\n",
    "---\n",
    "\n",
    "#### `torch_dtype` (`str` | `torch.dtype`, *optional*)\n",
    "Precisi√≥n usada en PyTorch (`float16`, `bfloat16`, `\"auto\"`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "#### `trust_remote_code` (`bool`, *optional*, por defecto `False`)\n",
    "Permite ejecutar c√≥digo personalizado de los repositorios.  \n",
    "**‚ö†Ô∏è Solo usar si conf√≠as en el c√≥digo.**\n",
    "\n",
    "---\n",
    "\n",
    "#### `model_kwargs` (`dict`, *optional*)\n",
    "Argumentos adicionales enviados al cargar el modelo con `from_pretrained()`.\n",
    "\n",
    "---\n",
    "\n",
    "#### `kwargs` (`dict`, *optional*)\n",
    "Argumentos adicionales pasados al inicializar el pipeline espec√≠fico.\n",
    "\n",
    "---\n",
    "\n",
    "### Pipelines Returns\n",
    "\n",
    "#### `Pipeline`\n",
    "Devuelve un objeto pipeline adecuado para la tarea especificada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d681f",
   "metadata": {},
   "source": [
    "### Pipeline Batching\n",
    "\n",
    "Todas las *pipelines* pueden usar *batching* peor tienes que darles algun objeto divisible -> List, Dataset, generator\n",
    "\n",
    "#### Pipeline Chunk Batching\n",
    "\n",
    "Existen casos como `zero-shot.classification` y `question-answering` que no es posible hacer la divisi√≥n de batches como quisieramos hacer de forma normal puesto que los datos de uno se utilizan para otro. Para ello hacemos:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89615b76",
   "metadata": {},
   "source": [
    "## Autoclasses\n",
    "Muchas veces, la arquitectura que queremos usar seguramente est√© en un *modelo preentrenado* al que podemos acceder usando el m√©todo `from_pretrained()`\n",
    "\n",
    "Es importante recordar que debemos usar el m√©todo `from_pretrained()` para indicarle que modelo estamos usando para todas las siguientes clases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88321621",
   "metadata": {},
   "source": [
    "### `AutoTokenizer`\n",
    "Sirve para cargar el **tokenizador** adecuado seg√∫n el modelo que est√©s usando. No hace falta que tu sepas cual hay que usar. \n",
    "\n",
    "Es importante recordar que debemos usar el m√©todo `from_pretrained()` para indicarle que modelo estamos usando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b95a2f0",
   "metadata": {},
   "source": [
    "### `Automodel`\n",
    "Es una clase que carga el **modelo base** de cualquier arquitectura soportada. \n",
    "\n",
    "El **modelo base** es:\n",
    "* El modelo **sin cabeza(head)** especifica para tareas\n",
    "* Solo incluye las capas fundamentales que generan las representaciones internas:\n",
    "    * **embeddings**\n",
    "    * **transformaciones internas**\n",
    "    * **hidden states**\n",
    "\n",
    "#### Funci√≥n exacta de `Automodel`\n",
    "1. <u>Detecta el modelo correcto a partir del identificador </u> que le pases (por ejemplo \"bert-base-uncased\") y carga autom√°ticamente la clase que corresponde (`BertModel`)\n",
    "2. <u>Carga los pesos preentrenados </u> del modelo base correspondiente.\n",
    "3. Ejecuta el modelo\n",
    "\n",
    "#### Salida de `Automodel`\n",
    "* `last_hidden_state`: tensor con la representaci√≥n final de la √∫ltima capa con la forma -> [batch_size, seq_len, hidden_dim]\n",
    "* Si activas `output_hidden_states=True` obtienes tambi√©n:\n",
    "    * `hidden_states`: tupla con la salida de cada capa del modelo\n",
    "* Si activas `output_attentions=True`\n",
    "    * Obtienes matrices de las *attention* internas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c743e3",
   "metadata": {},
   "source": [
    "### `AutoFeatureExtractor`\n",
    "Sirve para cargar autom√°ticamente el **extractor de caracter√≠sticas** adecuado para modelos *no basados en texto*.\n",
    "\n",
    "#### Adjunto \n",
    "En modelos recientes, esta clase est√° siendo reemplazada por `AutoImageProcessor` y `AutoProcessor`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
