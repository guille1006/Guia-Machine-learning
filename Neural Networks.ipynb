{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Neural Networks</h1>\n",
    "<h1 style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo Díaz Aguado</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción \n",
    "La idea central es extraer combinaciones lineales de las entradas como **features derivadas**, y luego modelizar el target como una función no lineal de esas features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection Pursuit Regression \n",
    "Como todos los problemas de aprendizaje supervisado, tenemos un vector de entrada X con *p* variables independientes y un target *y*. Usaremos unos pesos $\\omega_m$ siendo $m=1,2,...,p$. El *Prjection Pursuit Regression* PPR tendrá la forma:\n",
    "$$ \n",
    "f(X)=\\sum_{m=1}^{p}g_m(\\omega_{m}^TX)\n",
    "$$\n",
    "Donde muchas veces para simplificar usaremos:\n",
    "$$\n",
    "V_m = \\omega_{m}^TX\n",
    "$$\n",
    "\n",
    "La función $g_m(\\omega_{m}^TX)$ es llamada la *ridge function* in el espacio $\\mathbb{R}^p$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "Actualmente el nombre de red neural ha derivado en una gran cantidad de modelos y metodos de aprendizaje. Por ahora vamos a describir el modelo mas sencillo y basico (el modelo mas \"vanilla\") llamado tambien como el Perceptron de una capa oculta o the single layer back-propagation network. Usualmente son vistos como una especie de magia que proviene de los ordenadores, pero realmente se puede ver como modelos estadíticos no lineales. \n",
    "\n",
    "Son usados para problemas de clasificación y de regresión, en el caso de tener un problema de regresión nuestra capa fianl estará compuesta por un único nodo que nos indicará el resultado, en cambio si es un problema de clasificación con *k* posibles valores nuestra capa final estará compuesta por *k* nodos, donde cada uno tendrá su posibilidad de ser. \n",
    "\n",
    "Empezaremos con los nodos de nuestras variables independientes: $X^n$, todos estos nodos de inicio pasarán sus valores a cada uno de los nodos de la siguiente capa de nuestra red, dentro de cada nodo interno se calculará el valor de estos nodos internos como una función lineal de la capa anterior, nosotros lo llamaremos $Z_m$ donde *m* será el número de nodos de la capa \n",
    "$$ \n",
    "\\begin{align*}\n",
    "Z_m &= \\sigma(\\alpha_{0m}+ \\alpha_{m}^{T}X) && Z_m: \\text{Variable derivada} \\\\\n",
    "&                                          && \\sigma: \\text{Función de activación} \\\\\n",
    "&                                          && \\alpha_{0m}: \\text{bias} \\\\ \n",
    "&                                          && \\alpha_{m}^{T}: \\text{Peso para el nodo m de la capa T} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "* La **función de activación $\\sigma(v)$** será aquella que usaremos para hacer que los valores de cada nodo varien entre 0 y 1. \n",
    "* Realmente cada nodo asocia a los nodos anteriores un *bias*, pero como al final es una función lineal de la capa anterior, podemos juntar los *bias* como un único valor. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las unidades en la parte central de la red son llamadas *hidden unitis*, porque los valores de $Z_m$ no son observados directamente. Podemos imaginar los valores de $Z_m$ como una *expansión de las bases* de las entradas originales X; la **red neuronal** es entonces un modelo lineal estándard, o un modelo multilogistico lineal (usando estas transformaciones como entradas). Pero hay una mejora: en este caso los parametros de la función base son <u> aprendidos desde los datos</u>.\n",
    "Es por ello que, si la función de activación $\\sigma$ fuese la *función identidad*, entonces el modelo complpeto colapsaría en un modelo lineal.\n",
    "\n",
    "De tal forma, una red neuronal se puede describir como una generalización **no-lineal** de un modelo lineal mediante la introducción de la función de activación $\\alpha$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Neural Networks\n",
    "Las redes neuronales en un principio tienen parametros desconocidos: los **weights(pesos)**, es nuestro trabajo encontrar valores para estos pesos, y conseguir que el modelo encaje bien con los datos de entrenamiento. \n",
    "Tendremos nuestro set completo de pesos de la siguiente manera:\n",
    "$$\n",
    "\\begin{align*}\n",
    "{\\alpha_{0m}, \\alpha_m; m=1,2,\\dots, M}&\\quad M(p+1) weights \\\\\n",
    "{\\beta_{0k}, \\beta_k; k=1,2,\\dots,K} &\\quad K(M+1) weights\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "* Para regresión, usaremos el SSE *sum-of-squared errors* como nuestra medida de encaje (**función de error**)\n",
    "$$\n",
    "R(\\theta)=\\sum_{k=1}^K\\sum_{i=1}^N(y_{ik}-f_k(x_i))^2\n",
    "$$\n",
    "\n",
    "* Para clasificación podemos usar *squared error* o *cross-entropy* como **función de error**:\n",
    "$$\n",
    "R(\\theta)=\\sum_{k=1}^K\\sum_{i=1}^Ny_{ik}\\text{log}f_k(x_i)\n",
    "$$\n",
    "\n",
    "De forma general no queremos el **minimo global de $R(\\theta)$**, ya que es muy probable que nos de una solución <u>sobreajustada</u>. Para que no se dé el sobreajuste podremos hacerlo de varias formas:\n",
    "* De manera directa: Con un **término de penalización**\n",
    "* De manera indirecta: Con un **early stopping**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
