{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ac1e35",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 3em; font-weight: bold; text-align: center;\">Recurrent Neural Networks</div>\n",
    "<div style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo Díaz Aguado</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db151f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2660da",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "NLP es un subcampo de la lingüística, informática e inteligencia artificial que se ocupa de las **interacciones entre las computadoras y los lenguajes humanos(naturales)**. \n",
    "\n",
    "La diferencia entre el lenguaje natural (el usado en los idiomas) y los lenguajes de programación es que en estos últimos, primero se diseñan las reglas y después se usan estos programas, pero con el lenguaje natural pasa lo contrario.\n",
    "\n",
    "### Aplicaciones populares.\n",
    "* **Análisis de Sentimientos**: clasifica publicaciones como positivas o negativas. \n",
    "* **Extracción de información**: Creación de datos estructurados a partir de documentos no extructurados, realciones en textos largos (noticicas).\n",
    "* **Traducción de textos**:  Textos es un idioma que son traducidos a otro idioma.\n",
    "* **Respuesta a preguntas**: Ademas de reconocer el texto, también buscan y dan respuestas. \n",
    "* **Resumen de texto**: Pueden resumir textos largos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f848fb6",
   "metadata": {},
   "source": [
    "# 1. Inicio -> Prepararación de los datos.\n",
    "Como sabemos de la teoría, nosotros solo podemos procesar tensores númericos. Debemos **Vectorizar el texto**: transformar el texto en tensores númericos.\n",
    "\n",
    "Hay muchas formas de **Vectorizar texto** pero la mayoría sigue la siguiente estructura:\n",
    "* *Estandarizamos* el texto para hacerlo fácil de procesar.\n",
    "* Dividimos el texto en *unidades/tokens*\n",
    "* Convertimos cada token en vectores númericos. Para poder hacerlo ya deberíamos haber *indexado* todos los tokens presentes en los datos.\n",
    "\n",
    "## 1.1 Estandarización del texto.\n",
    "Realmente esto es una forma básica de *feature engineering* que evita codificar elementos que no quieres que tu modelo deba entender.\n",
    "\n",
    "Algunos puntos importantes serían:\n",
    "* Convertir todo en minusculas.\n",
    "* Quitar los simbolos de puntuación.\n",
    "* Transformar los carácteres especiales en sus formas estandars\n",
    "* *Stemming*: convertir diferentes variaciones de un término en una representación compartida.\n",
    "\n",
    "Con estas estandarizaciones, el modelo conseguirá de forma más sencilla llegar a generalizaciones. También hay que tener en cuenta que se pierde algo de información al estandarizar el texto.\n",
    "\n",
    "## 1.2 Tokenization: Text splitting.\n",
    "Ahora necesitamos que el texto se divida en unidades (*tokens*) para que se pueda vectorizar, se puede hacer de las siguientes maneras:\n",
    "* **Word level tokenization**. Donde cada token está separado por espacios. una variante sería dividir cada palabra en subpalabra: staring->stare+ing, called->call+ed.\n",
    "* **N-gram tokenization**. Donde cada token es un grupo de N palabras consecutivas.\n",
    "* **Character-level tokenization**. Donde cada caracter es un token.\n",
    "\n",
    "Suele haber dos tipos de modelos de procesamiento de texto:\n",
    "* **Sequence models** -> Aquellos a los que le importa el *orden* de las palabras. -> Usar word-level tokenization\n",
    "* **bag-of-words models** -> Aquellos que tratan las palabras sin tener en cuenta el orden. -> usar N-gram tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd12d49",
   "metadata": {},
   "source": [
    "\n",
    "## 1.3 Indexado del vocabulario.\n",
    "Una vez tenemos dividido el texto ya podemos **encode** o codificar cada token a un valor númerico.\n",
    "\n",
    "### 1.3.1 Mediante un diccionario.\n",
    "Simplemente usaremos un diccionario que para cada token le tendremos asignado un valor númerico. Esto sería inviable para textos muy largos, por lo que tendremos 2 valores especiales.\n",
    "* 1-> \"Out Of Vocabulary\". Para palabras que no han sido registradas\n",
    "* 0-> \"Mask token\". Para cuando queramos decir que un token está vacío. Esto es útil cuando usamos bathces de texto donde cada batch no tiene por que tener el mismo número de tokens.\n",
    "\n",
    "### 1.3.2 Mediante `TextVectorization`\n",
    "Esta capa lo que realiza es:\n",
    "* Realiza un indexado de las palabras del texto.\n",
    "* Encoder:\n",
    "    * Estandarizado de texto.\n",
    "    * Tokenización de texto.\n",
    "    * Indexa el texto.\n",
    "* Decoder:\n",
    "    * Desindexa los tokens.\n",
    "\n",
    "##### Uso de la capa \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b915502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TextVectorization name=text_vectorization, built=False>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False,\n",
    "    vocabulary=None,\n",
    "    idf_weights=None,\n",
    "    sparse=False,\n",
    "    ragged=False,\n",
    "    encoding=\"utf-8\",\n",
    "    name=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0d58d",
   "metadata": {},
   "source": [
    "\n",
    "* `max_tokens`: Tamaño máximo del vocabulario.\n",
    "    * Solo se debería especificar cuando `pad_to_max_tokens=True`\n",
    "    * Contiene el token **OOV**, por lo que el tamaño efectivo siempre será $\\text{max\\_tokens}-1$\n",
    "* `standarize`: Estadarización que se la va a aplicar al texto de entrada.\n",
    "    * `None`: Sin estandarizar.\n",
    "    * `\"lower_and_strip_puntuation\"`(por defecto): En minusculas y sin signos de puntuación.\n",
    "    * `\"lower\"`: En minusculas\n",
    "    * `\"strip_punctuation\"`: Sin signos de puntuación.\n",
    "    * \"callable\": Se le puede pasar una función para estandarizar.\n",
    "* `split`: Tokenización del texto.\n",
    "    * `None`: Sin dividir.\n",
    "    * `\"whitespace\"`: Dividir en los espacios.\n",
    "    * `\"character\"`: Dividir en cada caracter de unicode.\n",
    "    * \"callable\": Se le puede pasar una función para dividir.\n",
    "* `ngrams`:\n",
    "* `output_mode`: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
