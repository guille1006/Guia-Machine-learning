{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ce45b6",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"> Support Vecto machine </h1>\n",
    "<h1 style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo Díaz Aguado</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28add09b",
   "metadata": {},
   "source": [
    "# Definición Máquinas de Vector Soporte\n",
    "## Hiperplanos\n",
    "En un espacio p-dimensional, un **hiperplano** es un subespacio plano afín de p-1 dimensiones. La ecuación para estos planos sería algo tal que así:\n",
    "\n",
    "$$\n",
    "\\beta_0X_0+\\beta_1X_1+...+\\beta_pX_p=0\n",
    "$$\n",
    "\n",
    "Donde todos los puntos donde se verifique la ecuación anterior estarán incuidos en el hiperplano. El hiperplano divide el espacio 3 partes:\n",
    "* Aquellos puntos incluidos en el hiperplano:\n",
    "$$\n",
    "\\beta_0X_0+\\beta_1X_1+...+\\beta_pX_p=0\n",
    "$$\n",
    "* Aquellos puntos por encima del hiperplano:\n",
    "$$\n",
    "\\beta_0X_0+\\beta_1X_1+...+\\beta_pX_p>0\n",
    "$$\n",
    "* Los puntos que están por debajo del hiperplano:\n",
    "$$\n",
    "\\beta_0X_0+\\beta_1X_1+...+\\beta_pX_p<0\n",
    "$$\n",
    "\n",
    "Como el hiperplano divide el espacio en 2 partes, podemos utilizar esta herramienta para que aquellas observaciones con sus caracteristicas $X_p$ den un valor mayor al del hiperplano corresponderán a una clase, y las que den un valor menor corresponderán a la otra clase. \n",
    "\n",
    "## The Maximal Margin Classifier.\n",
    "De forma general, si existe un hiperplano que pueda dividir nuestros datos en 2 subespacios, entonces existirán infinitos hiperplanos que puedan dividir nuestras muestras. \n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"Imagenes_SVM/planos_separadores.png\">\n",
    "</div>\n",
    "Como podemos ver en la gráfica de la izquierda de la imagen anterior, todos los planos mostrados son capaces de divir las muestras según su clasificación, pero no todas lo hacen de la misma manera, así que debemos elegir aquel plano que mejor lo haga, pero ¿Como lo hacemos?\n",
    "Usando el <span style=\"color: IndianRed;\">Maximal Margin Hiperplane</span> (También conocido como el <i>plano separador óptimo</i>), el cúal sería el plano que esté <u>más separado de los puntos en el espacio</u>. Para encontrar dicho plano debemos calcular la distancia perpendicular desde cada observación al hiperplano separador.\n",
    "Aquella observación que tenga la <u>distancia más pequeña</u> será aquella que defina el <b>margen</b>. Y aquel hiperplano que tenga el <u>mayor <b>margen</b></u> será el plano que eligamos. \n",
    "La observación que tenga la <u>distancia más pequeña</u> es llamada como <b>support vector</b>, ya que \"soporta\" el margen maximo del hiperplano. El hiperplano decidido depende únicamente de estos <b>support vector</b>, por lo que cualquier movimineto de estas observaciones significará un movimiento de esto planos. Es por ello que los <u>valores atípicos tienen mucho peso</u>\n",
    "\n",
    "Aunque pensemos que el **Maximal Margin Classifier** es el que mejores resultados suele dar, también puede chocar con *overfitting*.\n",
    "\n",
    "### Caso No-Separable.\n",
    "En muchos casos, es imposible encontrar un hiperplano que sea capaz de dividir las muestras etiquetadas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ff7e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
