{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ce45b6",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"> Support Vecto machine </h1>\n",
    "<h1 style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo D칤az Aguado</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28add09b",
   "metadata": {},
   "source": [
    "# Definici칩n M치quinas de Vector Soporte\n",
    "## Hiperplanos\n",
    "En un espacio p-dimensional, un **hiperplano** es un subespacio plano af칤n de p-1 dimensiones. La ecuaci칩n para estos planos ser칤a algo tal que as칤:\n",
    "\n",
    "$$\n",
    "\\beta_0X_0+\\beta_1X_1+...+\\beta_pX_p=0\n",
    "$$\n",
    "\n",
    "Donde todos los puntos donde se verifique la ecuaci칩n anterior estar치n incuidos en el hiperplano. El hiperplano divide el espacio 3 partes:\n",
    "* Aquellos puntos incluidos en el hiperplano:\n",
    "$$\n",
    "\\beta_0X_0+\\beta_1X_1+...+\\beta_pX_p=0\n",
    "$$\n",
    "* Aquellos puntos por encima del hiperplano:\n",
    "$$\n",
    "\\beta_0X_0+\\beta_1X_1+...+\\beta_pX_p>0\n",
    "$$\n",
    "* Los puntos que est치n por debajo del hiperplano:\n",
    "$$\n",
    "\\beta_0X_0+\\beta_1X_1+...+\\beta_pX_p<0\n",
    "$$\n",
    "\n",
    "Como el hiperplano divide el espacio en 2 partes, podemos utilizar esta herramienta para que aquellas observaciones con sus caracteristicas $X_p$ den un valor mayor al del hiperplano corresponder치n a una clase, y las que den un valor menor corresponder치n a la otra clase. \n",
    "\n",
    "## The Maximal Margin Classifier.\n",
    "De forma general, si existe un hiperplano que pueda dividir nuestros datos en 2 subespacios, entonces existir치n infinitos hiperplanos que puedan dividir nuestras muestras. \n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"Imagenes_SVM/planos_separadores.png\" style=\"width:50%;\">\n",
    "</div>\n",
    "Como podemos ver en la gr치fica de la izquierda de la imagen anterior, todos los planos mostrados son capaces de divir las muestras seg칰n su clasificaci칩n, pero no todas lo hacen de la misma manera, as칤 que debemos elegir aquel plano que mejor lo haga, pero 쮺omo lo hacemos?\n",
    "Usando el <span style=\"color: IndianRed;\">Maximal Margin Hiperplane</span> (Tambi칠n conocido como el <i>plano separador 칩ptimo</i>), el c칰al ser칤a el plano que est칠 <u>m치s separado de los puntos en el espacio</u>. Para encontrar dicho plano debemos calcular la distancia perpendicular desde cada observaci칩n al hiperplano separador.\n",
    "Aquella observaci칩n que tenga la <u>distancia m치s peque침a</u> ser치 aquella que defina el <b>margen</b>. Y aquel hiperplano que tenga el <u>mayor <b>margen</b></u> ser치 el plano que eligamos. \n",
    "La observaci칩n que tenga la <u>distancia m치s peque침a</u> es llamada como <b>support vector</b>, ya que \"soporta\" el margen maximo del hiperplano. El hiperplano decidido depende 칰nicamente de estos <b>support vector</b>, por lo que cualquier movimineto de estas observaciones significar치 un movimiento de esto planos. Es por ello que los <u>valores at칤picos tienen mucho peso</u>\n",
    "\n",
    "Aunque pensemos que el **Maximal Margin Classifier** es el que mejores resultados suele dar, tambi칠n puede chocar con *overfitting*.\n",
    "\n",
    "## Caso No-Separable -> Support Vector Classifier\n",
    "En muchos casos, es imposible encontrar un hiperplano que sea capaz de dividir las muestras etiquetadas, o incluos puede haber planos que dividan las muestras, pero estos planos (debidos a su poca generalizaci칩n) no son deseables. \n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"Imagenes_SVM/influencia_de_una_observacion.png\" style=\"width:50%;\">\n",
    "</div>\n",
    "Como podemos ver en el caso anterior, en la izquierda tenemos un hiperplano que separa bastante bien las dos clases. En la gr치fica de la derecha, hemos a침adido un punto que modifica completamente el hiperplano anterior, perdiendo generalidad al solo implementar 1 punto. \n",
    "Es por eso que tal vez pueda ser rentable disclasificar algunas observaciones que 칰nicamente a침aden ruido o error al modelo, para as칤 conseguir mas:\n",
    "* Mayor robustez a observaciones individuales.\n",
    "* Mayor clasificaci칩n para la mayor칤a de las observaciones de entrenamiento.\n",
    "El <b>Suport vector classifier</b>, tambi칠n llamado como <b>Soft Margin Classifier</b>, lo que hace es: en vez de buscar el mayor <i>margen</i> posible, permite que algunas observaciones est칠n en el lado incorrecto del margen, incluso en el lado incorrecto del subespacio -> Es por esto que se llama <b>margen suave</b> (porque no es un margen estricto). \n",
    "En la imagen siguiente se muestra un ejemplo de como ser칤an este tipo de observaciones.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"Imagenes_SVM/clasificador_por_margen_suave.png\" style=\"width:50%;\">\n",
    "</div>\n",
    "\n",
    "A modo de resumen: Un <b>Support Vector Classifier</b> elige un hierplano que es capaz de separar <u>la mayoria de las observaciones de training</u>, pero tal vez <u>algunas observaciones se clasisfican incorrectamente</u>\n",
    "\n",
    "Existe un hiperparametro <b>C</b> que se puede entender como una especie de \"budget\" a la cantidad de <i>margen</i> que puede ser violado por las <i>n</i> observaciones.\n",
    "* Si usamos **C**=0, entonces estariamos clasisficando con *MAximal Margin Classifier*\n",
    "\n",
    "En la pr치ctica **C** es un hiperparametro que se calcula mediante **Cross-validation**. Este hiperparametro controla el *bias-variance trade-off*.\n",
    "* Cuando **C** es peque침o: buscamos *margenes peque침os* -> lo que nos da **Baja bias** pero **Alta Varianza**. Tambien indicar치 que habr치 pocos *support vectors*\n",
    "* Caundo **C** es alto: tendremso *margenes altos* -> lo que nos da **Alta bias** pero **Baja Varianza**. Tambi칠n habr치 muchos *support vectors*\n",
    "\n",
    "| Valor de **C** | Margen          | Bias        | Varianza     | N췈 de Support Vectors |\n",
    "|----------------|------------------|-------------|--------------|------------------------|\n",
    "| **Peque침o**    | *Peque침o*        | **Bajo**    | **Alto**     | *Pocos*                |\n",
    "| **Alto**       | *Grande*         | **Alto**    | **Bajo**     | *Muchos*               |\n",
    "\n",
    "En la siguiente imagen podemos ver ejemplos de distintos valores para el hiperparametro **C**\n",
    "\n",
    "|                      | **Izquierda**            | **Derecha**              |\n",
    "|----------------------|--------------------------|---------------------------|\n",
    "| **Arriba**           | 游댴 Mayor valor            | 游댴 Segundo valor m치s alto |\n",
    "| **Abajo**            | 游댵 Tercer valor m치s alto  | 游댵 Valor m치s bajo         |\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"Imagenes_SVM/diferentes_valores_C.png\" style=\"width:50%;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ff7e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
