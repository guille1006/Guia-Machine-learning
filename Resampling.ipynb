{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"> Resampling </h1>\n",
    "<h1 style=\"text-align: right; font-size: 24px; margin-right: 10px;\">Guillermo Díaz Aguado</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling methods\n",
    "Se basa en volver a realizar un resampleo de las muestras de un set de entrenamiento y volver a fittear el modelo de interés para cada muestra, para asi conseguir informacion adicional del modelo creado.\n",
    "\n",
    "Para entender que son este tipo de métodos debemos saber la diferencia entre el *test error rate* y el *training error rate*.\n",
    "\n",
    "* El *test error rate* es el error medio que resulta de usar un método de aprendizaje estadístico para predecir la respuesta de nuevas observaciones, estas son las muestras de test. Se desea que este sea siempre lo menor posible, ya que esta prediciendo correctamente puntos nuevos que no han sido usados para entrenar\n",
    "* El *training error rate* es el error medio que resulta de usar un método de aprendizaje estadístico en las muestras de entrenamiento.\n",
    "\n",
    "En el caso de no tener las muestras de test suficientes para verificar que nuestro *test error rate* es real, debermos usar algunas de las siguientes técnicas para poder acercarnos mejor a una repsuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "En este caso usaremos parte de las muestras que tenemos de entrenamiento como muestras de test.\n",
    "\n",
    "### The validation Set Approach.\n",
    "Es una tarea sencilla que involucra dividir de manera aleatoria nuestros datos observados en dos partes: set de entrenamiento y set de test. El model se crea basándonos en el set de entrenamiento y el error de test se reaaliza usando las ubservaciones guardadas en test (generalmente se usa el MSE).\n",
    "\n",
    "Como la división entre training y test es aleatoria, si realizamos otra división, entonces nos saldrá distintos valores de MSE para cada división.\n",
    "\n",
    "Dos de las mayores desventajas de este proceso son:\n",
    "\n",
    "·       La estimación del *test error* puede variar bastante entre divisiones\n",
    "\n",
    "·       Solo se usan una parte de las muestras observadas para entrenar al modelo, la otra parte se usa para test\n",
    "\n",
    "### Leave-One-Out Cross-validation LOOCV\n",
    "Es muy parecida al Validation set aproach, pero intenta resolver sus desventajas\n",
    "\n",
    "Se basa en dividir las observaciones en dos partes. Pero en vez de crear dos set de datos con tamaños similares, se crea un set de test con 1 SOLA OBSERVACION y el resto se usa para training.\n",
    "\n",
    "Usaremos esta única observación predictiva para realizar el MSE, la ventaja es que al haber usado todas las obsevaciones disponibles, el modelo se habrá entrenado con casi todas y será unbiased, el problema es que si solo nos basamos en esta observación , existirá mucha varianza. Así que deberemos realizar este proceso con las demás muestras y sacar la media del MSE.\n",
    "\n",
    "$$\n",
    "CV_{n} = \\frac{1}{n} \\sum_{i=1}^{n} MSE_i\n",
    "$$\n",
    "\n",
    "Las ventajas de este procedimiento son:\n",
    "\n",
    "* Tiene menos sesgo o bias\n",
    "* Usa la mayoría de las observaciones, con lo cual no sobreestima tanto el error\n",
    "* No depende de la aleatoriedad\n",
    "\n",
    "Las desventajas son:\n",
    "* Son muchos cálculos, por que tienes que hacerlo n veces, con lo cual tarda mucho\n",
    "\n",
    "### k-fold Cross-Validation -> Validacion cruzada\n",
    "Este proceso se basa en dividir las obsevaciones en *k* grupos de aproximadamente el mismo tamaño. El primer grupo será el de validación en la primera iteracción, con este pimer grupo como test y los demás *k-1* grupos que serán los de test, calcularemos el error para ese modelo. Repetimos este proceso usando los demás *folds* como test.\n",
    "\n",
    "Se relaiza de la siguiente forma:\n",
    "\n",
    "Desde i=1 hasta k:\n",
    "    El gupo i es de test\n",
    "    Construir modelo con el resto de grupos\n",
    "    Estimar el error\n",
    "Realizar la media de los errores\n",
    "\n",
    "$$\n",
    "CV_{k} = \\frac{1}{n} \\sum_{i=1}^n Error estimado\n",
    "$$\n",
    "\n",
    "Como se puede observar el LOOCV es un caso especial de CV, la mayor ventaja que hay con respecto a lo anterior es el tiempo computacional usado\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias variance Trade-off for K-Fold Cross-Validation\n",
    "Un potencial que tiene la validación cruzada con respecto a LOOCV es que hay veces que puede dar una mejor estimación del error, esto tiene que ver con el trade-off entre bias-variance.\n",
    "\n",
    "Como hemos visto en los anteriores apartados,\n",
    "\n",
    "* **SESGO**:Validation set aproach sobreestima la tasa de error , puesto que se usan unas cuantas muestras para training y otras para test, lo cual hace que sea sesgada. En cambio LOOCV al usar la media de la tasa de error medio entre todas las observaciones, entoces será sin sesgo. Para cross validation existirá una un nivel intermedio de sesgo, puesto que une ambos mundos.\n",
    "* **VARIANZA**: Ahora en la varianza, sabemos que el LOOCV es el que mas varianza tiene porque solo utiliza una observación en el test\n",
    "\n",
    "### Cross validation en problemas de clasificación.\n",
    "## BOOTSTRAP\n",
    "Se basa en la idea que en vez de intentar sacar set de datos independientes constantemente desde la población real (lo cual sería muy caro), obtendremos distintos datasets mediante el **remuestreo constate desde el dataset original**. Los remuestreos se realizan con **REEMPLAZAMIENTO**, lo que significa que una observación puede ser escogida varias veces en el dataset creado por el bootstrap.\n",
    "\n",
    "En el Bootstrap debemos indicar 2 hiperparametros:\n",
    "\n",
    "* *B*: número de veces que vamos a crear un Bootstrap dataset.\n",
    "\n",
    "* *N*: Numero de observaciones para el Bootstrap datset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
